# Ep 01
# 모델링

- 개논물

## 개념 모델링
- 일반적으로 생략됨
- 개체관계 다이어그램이 주요 산출물

## 논리 모델링
- 업무 분석
- 정규화
- 엔터티 속성 관계 도출

=> 업무에 대한 이해도 요구

## 물리 모델링
- DBMS 벤더별  최적 컬럼 타입 선정
- 접근 패턴 분석
- 반정규화
- 인덱스 전략수립

=> DBMS에 대한 이해도 요구, 큰 기업에서는 DBA 업무영역


# CHAR vs VARCHAR

## 공통점
- 문자열 저장용 컬럼
- 최대 저장 가능 문자 **길이** 명시(바이트 수 아님!)
- 실제 바이트수는 어떤 문자셋을 사용하느냐에 따라 달라진다
  - 만약 라틴1 문자셋이면 10자 기준 10바이트지만 utf-8은 10~40바이트까지 가능


## 차이점
- 값의 실제 크기에 관계없이 고정된 공간 할당 여부
  - char는 남는 공간을 공백으로 채워 무조건 바이트를 채워넣음
  - char - utf8mb4 기준으로 특이한  동작은 예약공간이 CHAR(10)이라할때 30~40 바이트가 아니라 기본 10바이트이며 4글자 이상으로 12바이트이상 넘어가면 남는 공간이 없이 저장되도록 동작하여 나름 최적화가 일어난다
  - varchar는 사용한만큼만 쓰는 동적셋
- 최대 저장길이 : CHAR(255) vs VARCHAR(168383) -> 65535 바이트
- 저장된 값의 길이 관리 여부
  - varchar는 저장 길이가 가변이므로 해당 데이터의 길이관리를 위해 1~2바이트의 길이 바이트 저장공간이 별도로 필요하다
  - char도 utf쓰면 저장공간의 크기가 달라지므로 결국 길이 관리를 해야해서 저장공간이 필요하다
  - 결국 둘다사용!


# 그래서 어떤걸 쓸까?

## 일반적으로 알고있는 구분기준
  - 고정된 길이값
  - 하지만 실무에서 큰 의미는 없다

## 실무적인 기준
- 가변폭의 크기 / update 빈도(특히 인덱스된 경우 CHAR가 유리)
- 저장되는 값의 길이 변동이 크지 않다면 CHAR의 낭비도 큰건 아님

### 공백공간의 의미?
update시 기존 공간보다 커서 대체할수 없는상황이라면 postgre처럼 기존 공간을 delete marking하고 새롭게 빈 공간에 레코드를 저장


____

# EP 02

# 공통점

- 문자열 속성값을 저장
- 최대 65,535 바이트까지 저장가능

# 차이점
- VARCHAR 타입 컬럼에는 지정된 글자수만큼만 데이터 저장가능
- TEXT 타입 컬럼은 인덱스 생성시 반드시 Prefix 길이 지정 필요
  - 인덱스 사이즈 제한도 존재
- TEXT 타입 컬럼은 표현식으로만 디폴트 값 지정 가능


# VARCHAR vs TEXT

- 일반적인 사용 형태 : 길이가 짧으면 VARCHAR, 길이가 길면 TEXT
  - 명확하지 않음

## 실무적인 기준

### VARCHAR(5000) vs TEXT

- VARCHAR 타입은 메모리 버퍼 공간을 미리 할당해두어 재활용이 가능하기때문에 컬럼사용이 빈번한경우 캐시사용관점에서 VARCHAR가 더 유리
- 다만 메모리 사용량은 더 높아질수 있다

### BARCHAR(30) vs VARCHAR(255)

- 실제 최대 사용하는 길이만큼 명시하는것이 메모리 사용 효율상 좋음


# VARCHAR & TEXT 주의사항

- VARCHAR도 저장되는 값의 사이즈가 크면 OFF - Page 형태로 데이터가 저장됨
  - 포인트 값 20바이트 외에는 별도 페이지저장

= external page, overflow page라고 부름

## 성능차이

- external page는 거의 4배 차이가 날수도있다!
- 꼭 필요한게 아니라면 select 제외하기



___

# EP 03
# 잘못된 기대

- COUNT (*) 쿼리는 Select *    보다 빠를것이라 기대하지만 실제로는 동일한 수준인 경우가 많음
  - 예시로서 where절에서 인덱싱이없는경우 전체 데이터를 풀스캔해야하므로 결과적으론 select * 과 차이가 없어짐
- ORM에서 자동 생성된 쿼리 실행
  - 페이지네이션중 COUNT(DISTINCT(id))로 쿼리가 날라가는 경우도 존재한다

# COUNT(*) vs COUNT(DISTINCT expr)
- COUNT(*) 는 레코드 건수만 확인
- COUNT(DISTINCT expr)은 심시 테이블로 중복 제거후 건수 확인
  - 중복 레코드 제거를 위해 임시 테이블을 세팅하고 이에 저장해야함
  - 임시테이블에 insert시 select and check insert하므로 굉장히 부하가 크다!



#  성능개선은 어떻게해야할까?
- BEST : Covering Index 사용하기
- 혹은 페이지번호가 필요한 쿼리 자체가 없도록하는것(이건 결국 비즈니스의 결정....)
- 임의의 레코드 건수 표시하기(처음에는 10페이지까지 나오다가 실제 3페이지를 누르면 그때 페이징으로 표시하는 방법, 구글방식)
- 통계정보 이용하는 방법

# COUNT(*) 튜닝
- 제거대상
  - where 조건없는COUNT(*)
  - where 조건에 일치하는 레코드 건수가 많은경우


- 인덱스를 활용하여 최적화 대상
  - 정확한 COUNT(*) 가 필요한경우
  - COUNT(*) 대상 건수가 소량인 경우
  - where 조건이 인덱스로 처리될 수 있는경우


# 결론은
ORM 믿지말고 모든 쿼리를 다 확인해보자


____

# EP 04

# 페이징 쿼리 

## LIMIT & OFFSET

- 많은 부하가 생김
- OFFSET을 바로 넘어가는게 아닌 읽어서 넘어가기떄문

## 범위기반 방식
- 날짜 기간이나 숫자 범위로 나눠서 데이터를 조회하는 방식
- LIMIT대신 WHERE 절에서 조회범위를 직접지정


## 데[이터 개수기반방식
- 지정된 데이터 건수만큼 결과 데이터를 반환하는 형태로 구현된 방식
- 배치보다는 주로 서비스단, 쿼리에서 ORDER BY & LIMIT 절이 사용됨
- 처음 쿼리를 실행할 때와 그 이후 쿼리를 실행할 때 쿼리 형태가 달라짐
- 쿼리의 WHERE절에서 사용되는 조건 타입에 따라서 N회차 실행시의 쿼리형태도 달라짐

____

# EP 05

# MySql Function

- 빌트인
- UDF
- Stored Function


# Deterministic Or Not Deterministic

- 멱등성과 동일한 개념
- 기본 속성은 Not deterministic!
- 입력이 동일하면 출력이 항상 동일한지 여부를 mysql에 알려주는 힌트역할
- 만약 not Deterministic이면 최적화 과정에서 해당 함수를 여러번 호출하여 가장 최신값을 사용하려하기때문에 연산비용이 훨씬 많이 들게 된다
- 또한 not deterministic은 인덱스 최적화가 불가능

# NOT DETERMINISTIC 함수들

- RAND()
- UUID()
- SYSDATE()
- 등등

# NOW 와 SYSDATE

- now는 Deterministic처럼 동작함
- sysdate is now 옵션으로 sysdate도 now처럼 동작하게 할 수 있음


  ___

  # EP 06

  # 파생테이블의 한 종류


- 파생테이블(derived Table) 은 쿼리의 from 절에서 서브쿼리를 통해 생성되는 임시 테이블을 의미
- 일반적으로 derived table은 선행 테이블의 컬럼을 참조할 수 없으나 lateral derived table은 참조가 가능하다
- 사용법은 정의된 derived table 앞부분에 lateral 키워드를 추가해서 사용
- 참조한 값을 바탕으로 동적으로 결과 생성


____

# EP 07

# 격리수준 복습

- mysql은 mvcc를 사용해 락없이 일관된 읽기를 구현한다
- 기본 격리수준은 repeatable read
- 트랜잭션 시작 직전 가장 마지막 커밋된 데이터를 해당 트랜잭션이 끝나기 전까지는 동일하게 조회하는것이 보장된다

# FOR UPDATE

- 배타락
- 격리 수준과는 무관하게 항상 최신 커밋 데이터 조회
- 단순 SELECT와 다른 결과 반환 가능함

~~~
	•	수정: 불가능 (다른 트랜잭션에서 해당 레코드를 수정하려고 하면 대기).
	•	FOR UPDATE 잠금 설정: 불가능 (대기).
	•	FOR SHARE 잠금 설정: 불가능 (대기).
	•	일반 조회 (SELECT): 가능.
~~~

## SELECT FOR UPDATE가 필요한 예시

- 잔액을 소모하는 비즈니스 로직이 있다고할때 트랜잭션으로 묶어놓더라도 해당 요청이 따닥이 되면 동시차감되므로 락이 필요하다
- 이때 유저락과같은 글로벌락을 사용할 수 있지만, SELECT FOR UPDATE를 통해 해당 레코드락을 걸수 있다.


# FOR SHARE
- 공유락
- SELECT FOR SHARE = s-lock
- 참조되는 부모테이블과 참조하는 자식테이블이 있고 자식테이블에 insert를 할때 부모테이블이 삭제되는것을 방지하기 위해 락을 거는 기법

~~~
	•	수정: 불가능 (다른 트랜잭션에서 해당 레코드를 수정하려고 하면 대기).
	•	FOR UPDATE 잠금 설정: 불가능 (대기).
	•	다른 FOR SHARE 잠금 설정: 가능.
	•	일반 조회 (SELECT): 가능.
~~~

for update와 차이점은 동일목적으로 select for ~  조회시 가능하냐 여부

## 주의점

- select 이후에 update할 확률이 높다면 for share를 사용시 락 업데이트가 필요하고 이때 데드락 위험성이 커지므로 차라리 처음부터 for update를 사용하도록 하자



# JPA Optimistic vs Pessimistic?

- Optimistic Lock은 JPA에 대한거지 mysql에 대한것이 아니므로 논의대상이 애초에 아니다

## JPA Optimistic Lock

- 레코드의 버전을 할당하여 원하지 않는 UPDATE 실행 방지
- 실제 MYSQL서버가 제공하는 잠금기법은 아님

## Pessimistic Lock 

- FOR UPDATE쓰는 방식


____

# EP 08

# Generated Column ?

- 표현식으로 정의된 컬럼
- 정의도니 표현식에 따라 컬럼의 값이 자동으로 생성
- 종류
    - 버추얼 컬럼
    - 스토어드 컬럼

## 생성법

~~~
col_name data_type [GENERATED ALWAYS] AS (expr)
[VIRTUAL | STORED] [NOT NULL | NULL]
[UNIQUE [KEY]] [[PRIMIRY] KEY]
[COMMENT 'STRING']

// 또는
ALTER TABLE TEST ADD COLUMN GENERATED_COLUMN AS (COL1 + COL2) VIRTUAL;

~~~

- 기본적으로 VIRTUAL 타입으로 생성 & NULL 값 허용
- primiary key로는 stored만 가능
- 하나의. 테이블에서 가상 컬럼과 스토어드 컬럼 혼합해서 사용가능


# Virtaul Column 
- 컬럼값을 디스크에 저장하지않음
- 인덱스는 생성가능하다!
  - 인덱스는 디스크에 저장됨

# Stored Generated Column
- 컬럼의 값을 디스크에 저장
- 컬럼의 값은 레코드가 INSERT되거나 UPDATE될때 계산되어 저장
- 인덱스 생성가능
- 

# Generated Column 유효성 검사

-  Generated Column 추가또는 변경시 유효성을 검사해 생성 실패를 시키는 검사 옵션

##  without validation
   - 기본 설정
- 기존 데이터 무결성 확인하지 않으며, 가능한 경우 in place 방식으로 수행
- 계산된 값ㅇ ㅣ컬럼으 ㅣ값 범위를 벗어날 . 수있음


## with validation
- 테이블 데이터 복사 수행
- 작업중 DML유입시 잠금 대기(메타 데이터 락 대기) 발생
- 작업시 계산된 값이 컬럼의 값 범위를 벗어나는 경우 명령문 실패


# 인덱스 사용
- 일반 컬럼과 동일하게 쿼리에서 인덱스 사용가능
- 쿼리에 컬럼명 대신 표현식을 사용해도 인덱스사용은 간으하지만 컬럼에 정의된 표현식과 완전히 일치해야함
  - 그냥 이런건 쓰지말자


# 함수기반 인덱스
- 최신 스택임
- 표현식을 인덱스값으로 사용가능하여 수식을 사용하는 쿼리가 빈번하고 해당 컬럼을 추가하고싶지않을때 이러한 표현식 기반 인덱스를 생성하고 해당 표현식으로 조회 가능

## 동작방식
- 히든 가상 컬럼을 생성하고 해당 컬럼을 인덱싱하는 방식
- 히든 가상 컬럼은 일반적인 환경에서는 확인불가능하다

## 주의사항
- 인덱스 생성후 실행계획을 반드시 확인!
- 인덱스가 사용되지 않을수도 있으니까 항상 체크하자
- 같은 숫자여도 long 인지 double인지도 다를수 있으므로 표현식이 완전히 동일한지 확실히 확인해야한다
- 기본적으로 일반 인덱스보다 추가적인 계산 비용이 발생
- 표현식에 비결정적 함수 사용 불가능
- 공간 인덱스, 전문 검색 인덱스 지원x
- primiary key에 표현식은 포함 불가



____

# Online DDL

# 개념

- 테이블에 잠금없이 심리스하게 DDL 작업을 수행하는 기능
- 락이없고, 백그라운드에서 병렬로 수행되며, 로그재생을 통해 복원이 가능하고 에러시 롤백도 쉬운편이므로 운영레벨이라면 온라인 DDL을 쓰도록 하자
- https://dev.mysql.com/doc/refman/8.4/en/innodb-online-ddl-operations.html

# 주의점
- innodb_online_alter_log_max_size 임시 버퍼에 dml이 쌓이므로 많은 사용이 예상된다면 버퍼사이즈를 조절하는것도 방법
- Online DDL 작업시 실행알고리즘을 직접 명시하는것을 권장


____ 

# EP 09

# MYSQL 에러 구분

1. Global Error
- 범위 1~999
- 서버 클라이언트 모두 표준적으로 발생할수 있는 에러들    
2.  Server Error
- 범위 1000~1999
- mysql 서버 자체에서 발생하는 에러를 나타낸다
3. Client Error
- 범위 2000~2999
- 클라이언트에서 발생하는 에러로서 클라이언트 라이브러리에서 발생한느 문제와 관련이 있다. 드라이버가 내뱉는 경우가 많음



3000~는 서버대역

# SQL State
- 5글자 영문숫자로 구성
- ANSI-SQL에서 제정한 벤더 비의존적 에러 코드
- 앞의 두글자가 상태값의 분류이며 
  - 00 : 정상
  - 01 : 경고
  - 02 : 레코등벗음
  - HY : 아직 분류되지않음
  - 나머지는 모두 에러
- 뒤 세글자는 주로 숫자값이며 각 분류별 상세 에러코드 값

> ERROR 1062 (23000) <- mysql이 내뱉는 괄호안의 이 영문 숫자5개 포멧에 해당

- HY의 경우 미분류이기때문에 추후 분류를 통해 변경될수 있음을 알아두자(experimental이라고 생각하면됨)

# 에러 메시지
- 사람이 인식할 수 있는 문자열
- 에러메시지자체를 이용한 에러핸들링은 안좋은 방식이다 하지말자


# 에러핸들링은 위에 3개중 뭐로하는게 나을까?

- 지금까지의 히스토리상 sql state가 가장 변경이 없었다
- 표준스펙이기때문
- mysql 에러는 스토리지에 따라 동일한 에러도 다른 번호를 가지고있음을 명심하자
- 


# Best Practice
- DMA와 개발자간 가장 좋은 대화방법은 SQL문장과 ERROR 정보
- 애플리케이션레벨에서 DBMS의 에러를 버리는건 비추천하며 이를 래핑해서 사용할것
- ORM 사용시엔 DBMS에러와 응용프로그램 에러 구분
- DBMS 에러의 경우 반드시 같이 로깅!





____

# EP 10

# 대표적인 JOIN종류
- INNER JOIN은 교집합
- LEFT JOIN은 왼쪽 집합 + 교집합

# LEFT JOIN 정리

- LEFT JOIN 사용시 Driven Table(Inner Table, 오른쪽)컬럼의 조건(조인 조건)은 반드시 ON 절에 명시해서 사용
  - 왼쪽 테이블이 유지되는 효과가 있음
  - 반대로 필터링이 필요하다면 where절일거고 이럴경우는 inner join이 아닌가 검토 


___

# EP 11

# prepared statement는 jdbc기능?

- 놀랍게도 mysql도 prepared statement가 가능
- 정확히는 serverside / client side prepared statement가 존재하며 우리가 사용하는방식은 clientside preparedstatement로서 드라이버가 최종적으로는 완성된 쿼리를 mysql 서버로 전송한다

https://velog.io/@cjy9306/MySQL%EC%9D%98-PreparedStatement


# Binding Query

## 장점
- SQL Injection 방지
- 쿼리 파싱 비용감소(2번째 이후 실행)
  - 쿼리 재사용, 캐싱이 용이


## 단점
- 메모리 사용량 증가
- 2번의 네트워크 왕복이 필요(서버사이드 prepared statement사용시, 첫번째 실행시)
  - 실제 쿼리실행 이전에 prepared statement는 두번의 호출이 필요함
- 서버사이드 방식은 아직 실행계획을 캐싱하지않으며 Parse-Tree만 캐싱
- 커넥션 내에서만 prepared statement가 공유된다


# PreparedStatemnet vs ConnectionPool

- MySql 서버의 PreparedStatement는 하나의 Connection내에서만 공유됨
- 쿼리복잡도에 따라 트레이드 오프
- 메모리 vs CPU -> aws기준으로는 메모리가 적은편이므로 CPU연산집약적인 방식이 더 낫긴함

# 실무에서는?

- mysql 서버는 기존처럼 클라이언트 사이드방식이 권장
- 예상만큼 큰 성능향상은 없고 메모리소모는 큰편이다


____

# EP 12

# 가독성의 중요성

- 작성 의도를 보다 쉽게 이해할 수 있음
- 커뮤니케이션 비용 / 업무효율
- 문제 원인을 빠르게 찾을수 있으며, 실수 감소
- 유지보수에도 용이

# 방안
## DISTINCT를 함수처럼 사용하는 형태는 지양
- 괄호가 있건없건 동작은 똑같다. 괄호 없는게 더 나은 작성법

## LEFT JOIN 사용법 준수
- 드리븐 테이블에 대한 조건을 where절에 사용한다면 이는 inner join이 맞을확률이 높다. 필요한경우에만 left join을 사용하자

## ORDER BY절 없이 LIMIT을 사용하는 문법은 지양한다
- order By는 의도표현에 아주 중요하므로 명시적으로 쓰는것을 권장

## FULL GROUP BY 형태로 사용

- 그루핑 기준 컬럼 이외에 다른 컬럼을 select하는경우 항상 의도에 맞는 집계함수를 사용하여 의도를 표현하자

## AND / OR 조건 함꼐 사용 시 반드시 괄호 명시

- SQL 에서 AND 연산자는 OR 연산자보다 우선순위가 높아서 괄호를 반드시 명시하는게 더 나은 쿼리 작성법

## 데이터 건수 조회는 COUNT(*) 사용
- 다른 방식말고 그냥 * 쓰자, 어차피 동일한 동작 동일한 성능이다


____

# EP 13

# 콜레이션이란?
- 문자를 비교하거나 정렬할 때 사용하는 규칙
- 문자 집합과 관련된 개념으로 Collation은 특정 문자 집합에서 문자열을 어떻게 비교하고 정렬할지를 결정

        private const val RDB_COLLATION = "--collation-server=utf8mb4_unicode_ci"

문자집합 - 언어종속 - UCA버전 - 민감도 순이며

utf 유니코드 기본 언어비교전략이라고 보면 된다.

cs여야 대소문자까지 비교로 가중치로 사용된다

bin 또는 as_cs를 쓰자

## 주의사항

- 서로다른 콜레이션을 가진 컬럼들 값 비교시 에러가 발생한다

- 만약 쿼리를 통해 강제로 콜레이션을 변경하면 인덱스를 사용할수 없는 문제가 있다
- 애초부터 하나의 콜레이션으로 설정하는것이 바람직
- 기본 콜레이션 - 한글 비교 문제
  - utf8mb4_0900_ai_ci 는 가와 ㄱ ㅏ 가 같다!!!!
  - as_cs로 비교해야 구분이된다

![image](https://github.com/user-attachments/assets/9fa60c97-f8d9-4bd4-a20f-5f88472f1385)
 


____

# EP 14

# UUID Version

- 128비트 이진값
- 국제 표준에 정식으로 채택된 버전은 1~5
- 1,2는 timestamp기반
- 3,5는 해시기반
- 4는 완전랜덤
- 6은 표준에서 drop

## uuid ver 1
- timestamp를 쓰지만 이를 뒤섞고 있고, 100나노초 단위로 1씩 증가하다가 7분 10여초 단위로 첫번째 파트가 리셋
- 결론적으로 시간순 정렬이 불가능하댜


# UUID vs B Tree 관계 - primary key로 설정시 고려점
- 비트리는 자료구조상 리프 노드 구성시 순서대로 중간 노드를 형성하는데 UUID는 순차적인 생성방식이 아니기때문에 특정 노드에 키가 편중되다가 재정렬이 일어나는 문제가 발생할 수 있다
- 길이가 워낙 길고 secondary index는 기본적으로 primary index를 담기때문에 데이터 저장 공간이 많이 필요하다 

# 대안
- 8바이트(64비트) timestamp기반 아이디를 사용하는것이 실무적으로 더 낫다
- snowflake
- sonyflake

uuid는 비추다


____

# EP 15

> 인덱스가 있음에도 풀스캔이 일어나는 상황

# 컬럼이 가공되는 경우

인덱스가 걸린 컬럼을
- 연산
- 함수
- 형변환
  - orm과 같이 사용할때 특히 주의해야한다
 
이와같이 가공하면 인덱스를 사용할 수 없음


# 인덱싱 되지 않은 컬럼을 조건절에 or 연산과 함께 사용

# 복합 인덱스의 컬럼들중 선행 컬럼을 조건에서 누락

# LIKE연산에서 시작 문자열로 와일드 카드 사용

# 정규식 연산사용

# 테이블 풀스캔이 더 효율적인 상황

# NOT Equal , IS NOT NULL 일때 인덱스 사용여부?

- 옵티마이저 판단에 따라 인덱스를 쓰기도 함, 항상 사용하지 않는것이 아님





____

# EP 16 

# COUNT() 기본

- null이 아닌 값들만 반환하므로 특정 컬럼으로 count시 null이 포함된다면 총 레코드보다 적은 수가 반환된다

- 또한 NotNull이라고 명시되어있지않은 컬럼을 조회할경우 결국 체크가 필요하기때문에 인덱스의 풀스캔이 일어나 성능적으로도 매우 떨어지게 된다

 - 일반적으로 count(*)이 더 성능상 좋을 확률이 높음, 별도 컬럼을 왠만하면 쓰지 말자


____

# 커버링 인덱스

# 개념

- 쿼리의 모든 열을 인덱스에서만 가져올 수 있도록 설계된 인덱스
- 인덱스는 기본적으로 인덱스 key - value 형태이며 인덱스를 통해 원하는 데이터의 주소값이나 pk를 찾은 뒤 재 탐색을 해야하는 구조다. 이때 인덱스 안에 필요한 데이터가 전부 있다면 재탐색이 필요없어지므로 성능향상에 큰 이점이 있음


```
CREATE TABLE orders (
    order_id INT PRIMARY KEY,
    customer_id INT,
    order_date DATE,
    status VARCHAR(50)
);

CREATE INDEX idx_orders_customer_date ON orders (customer_id, order_date);
````



____

# EP 17 

# SELECT FOR UPDATE NOWAIT

- 잠금 대기하는것이 아니라 에러가 나는 방식
- 타임아웃없이 하기랑 동일
- 트랜잭션은 그대로 유지됨

# SELECT FOR UPDATE SKIP LOCK

- 잠금 대상 레코드 중에 다른 세션에 의해 이미 잠금이 걸려있는 레코드는 스킵하고 잠금이 걸려있지 않은 레코드를 잠그고 반환
- 따라서 잠금 대상 레코드가 비결정적
- 잠금 대상 레코드들이 모두 자금에 걸려있는 경우는 빈 결과를 반환
- ORDER BY & LIMIT 절과 함께 많이 사용
- 

# NOWAIT & SKIIP LOCKED with JOIN

- join시 드라이빙 테이블의 레코드가 락이 걸리면 skip락시 드리븐되는 모든 레코드들 탐색이 스킵되므로 굉장히 조심해서 사용해야한다
- 따라서 of 구문을 사용하여, 쓰고있는 드리븐 테이블만 락을 거는식으로 튜닝하는게 더 바람직!!!


____

# EP 18

# UNION 개념
- 두개 이상 쿼리 결과의 합집합
- 결과집합의 레코드 확장
- 임시테이블을 안쓰도록 튜닝해보자

# UNION ALL vs UNION DISTINCT

- 중복 제거 여부
- UNION DISTICT는 중복제거를 위해 무조건 임시테이블을 쓴다
- 그냥 UNION키워드만 사용하면 DISTICT가 기본동작이다!



=> 왠만하면 ALL을 쓰도록하자


____

# EP 19

# 컬럼정의

json_col1 json DEFAULT NULL | (json_object()) | (json_array())

# 저장구조

- 최적화된 바이너리 포멧
- 중복된 키가 있다면 마지막 순서의 데이터로 저장
- json 데이터 내 키들을 정렬해서 저장
- 키는 json 데이터마다 중복해서 저장되므로 키사이즈 고려도 필요

# JSON 데이터 조회

- $
- .
- []

# json 데이터 인덱싱도 가능

# TEXT vs JSON

- 최적화된 바이너리 포멧과 유효성 검사
- 부분 업데이트 가능
- 데이터 조회시 바이너리 json 데이터를 문자열 형식으로 변환후 전송


- 데이터를 저장 후 전체 데이터 조회하는 패턴으로 주소 사용하거나 json이 아니라면 TEXT
- json 데이터의 특정 키값만 주로 조회하고 변경시에만 json타입


_____

# EP 20

# Mysql DeadLock 감지

- 모든 트랜잭션이 획득 또는 대기하고있는 잠금 그래프를 그리고 감시
- 약간의 오버헤드가 존재하므로 이를 플래그로 off 시킬수 있음
  - DeadLock detection thread , innodb_deadlock_detect = off
  - 구글은 일부서비스에서 off
  - 만약 off시 실제로 데드락이 발생하면 타임아웃만큼 대기함(디폴트 50초), 튜닝할거라면 5초아래로 설정하자

# Mysql DeadLock 처리

- 롤백이 쉬운 트랜잭션을 희생 트랜잭션으로 선정
  - 롤백이 쉬운 트랜잭션 == Undo 레코드가 가장 적인 트랜잭션
- 희생 트랜잭셩르 강제 롤백하고 남은 트랜잭션은 정상처리

- 배치 작업과 서비스 쿼리가 경합한다면 항상배치 프로세스가 살아남게 됨


# MySql deadlock 해석 어려움


- 동일 SQL 문장이더라도 항상 동일한 잠금을 사용하는것이 아님
  - 현재 데이터의 상태 (삭제된 레코드의 경우 마킹형태로 남아 잠금을 하기도함)

   - 동시 실행중인 잠금 경합 DML(실행 시점)

- Record뿐 아니라 Record Gap락도 있고 next key lock도 있음
- 데드락 발생시점의 모든 상황을 로깅하지도 않고 로깅 정보도 부족한편
- auto_increment 관련 락은 statement단위이고 어떤건 transaction 단위 락이 걸리기도하다


# Deadlock에 대한 생각


## 많은 오해
- 프로그램 코드의 오류인가?, 개발능력의 부족인가?, 코드개선이 필요할까?
- 하지만 mysql 데드락은 회피할수 없는 경우가 더 많고 매우 드물게 발생하는경우도 많음
   - pk, uniquekey만 있는 테이블에 insert 경합만으로도 데드락이 발생할수도있음
  - unique Index 는 성능향상보다 데드락 가능성, 잠금 경합 빈도만 높이는경우가 많으므로 가능하면 제거하는 모델링을 하는것이 더 좋음

## 베스트 프랙티스 

- 애플리케이션 레벨에서 폴백을 통해 1차적으로 복구 시도
- 근본적인 원인을 없애려고 너무 노력하지 않아도 된다

____

# EP 21 Join Update/Delete

# UseCases

- 다른 테이블의 컬럼값을 참조해서 update/ delete하고싶은 경우

- 한번에 여러 테이블에 대해 update /delete 하고싶은 경우

# 주의사항

- 참조하는 테이블들의 데이터에는 읽기 잠금이 발생하므로 잠금 경합이 발생할 수 있음
- 1:N일때 생각보다 쿼리가 복잡하고 예상치 못하게 날라갈 수 있으므로 실행계획을 사전에 반드시 확인하자

____

# EP 22 커넥션 관리


# 개요

- Mysql은 오라클과 달리 스레드 기반으로 작동함
- 커넥션당 메모리 사용량이 적은편
- 스레드 풀을 사용하므로 더 작게 사용 가능
- 그래도 커넥션 갯수가 많아지는것에는 주의가 필요

## Max Conenction 설정

### server

-  Mysql max connection은 최대 1만개
-  Cf) postgre는 5k 이하(프로세스 자체의 메모리 사용량이 큰편)

### appserver(client)

- 커넥션풀을 일반적으로 사용
  - 커넥션 수를 최소화하는 역할, 오버헤드 감소
- 커넥션 풀은 시작시 2~30개정도면 적절함, 2코어인데 200? ㄴㄴ
- Min = Max * (70%~90%)
  - Min =  Max 설정이 성능상 좋긴하지만, 스파이크 예측이 힘드므로 약간의 여유가 있는게 나음
- 너무 과장된 커넥션 갯수는 피할것!
- 힘들경우는 미들웨어를 쓰는걸 고려하자

## 커넥션 풀 설정

### 커넥션 타임아웃설정
- 밀리초 이하의 값 설정을 권장하지 않음
- 인프라 여건에 맞춰 3~10초 정도의 시간 설정 사용
  - 커넥션을 가져오지 못할 경우 일반적으로 다른 폴백 전략이 없음


### 쿼리 타임아웃설정  
- 취소 및 동일 쿼리 재요청시 서버 부담 가중
- 쿼리타임아웃은 적절하게 길게, 너무 짧게 설정하면 불필요한 요청만 쌓인다

### idle 타임아웃 설정
- 8시간이상(기본값) 응답이 없다면 mysql에서 커넥션을 끊김
- 에러 회피를 위해 짧게 설정하는경우도 있는데 ㄴㄴ 최소 20~30분이상 설정 권장
- 커넥션풀의 커넥션은 왠만하면 라운드로빈 + validation을 하는방식이면 좋겠다
- 커넥션 에러시 retry도 고려해보기

# 미들웨어 사용
- Mysql Router
- ProxySQL
- RDS Proxy

- 미들웨어 수준에서 커넥션 풀 제공
- 운영비용, 트러블 슈팅 난이도 증가하므로 필요한경우에만 사용


## 주의사항

DNS RR을 하는 인프라에 DNS Cache를 하면 RR이 동작하지 않아 부하 분산이 안되는 문제가 생길 수 있음!

AWS Aurora에서 실제로 발생하는 문제

___

# EP 23 테이블 파티셔닝

## 테이블 파티셔닝이란?
- 하나의 테이블을 물리적으로 여러 테이브로 분할해서 데이터를 저장하는 기법
- 분할 기준은 다양

## 필요한 이유
- 삭제 가능한 이력 데이터들을 효율적으로 관리가능
  - 로그성 데이터들을 날짜별, 범위별 등으로 파티셔닝, 삭제가 쉬워짐
  - 삭제시 파티션 드랍
- 자원 사용 효율 증가 및 쿼리 성능 향상
  - 날짜 범위로 게시글을 파티셔닝하면 파티션 프루닝을 통해 리소스 최적화 가능
  - 파티션 프루닝으로 파티셔닝된 인덱스 조회가 가능해 쿼리 응답시간도 훨씬 단축될 수 있음


## 파티셔닝 타입
### 레인지
- 지정된 범위값에 따라 분할
- 실무에서 가장 많이 사용

### 리스트
- 지정된 값 목록 기준

### 해시
- 파티션 키

### 키
- 오로지 컬럼만

## 파티션 테이블 사용제약
- 외래키, 공간 데이터 타입, 전문검색 인덱스 불가능
- 일부 함수들은 파티션 프루닝이 불가능
- 테이블의 모든 고유키에 파티셔닝 기준 컬럼이 반드시 포함되어야함
- where절에 파티셔닝 기준 컬럼에 대한 조건이 포함되어 파티션 프루닝을 반드시 유도
- 값이 자주 변경되는 컬럼을 파티션 기준 컬럼으로 선정해서는 안됨



___

# EP 24 DBMS 주의사항


## 대용량 작업

### 개발자 side
- 최대한 굵고 짧게
- 동시에 많은 쓰레드로 빠르게 처리완료

### DBA side
- 가능한 가볍게(가능한 짧게)
- 소수의 쓰레드로 최소의 DBMS 리소스 소모
- 가늘고 길게 오래가 차라리 낫다

## 서버 처리 용량 고려

### onpremise
- 일반적으로 표준환경이였음

### 클라우드 환경

- db 스펙이 매우 다양하고 저사양 db 스펙도 많음
- 배치작업시 db스펙의 고려가 매우 중요

### 문제발생시 해결이 어렵다
- 슬로우 쿼리의 이유가 해당 쿼리가 아니라 배치로 인한 지연일수있고 이런것들을 역추적해서 원인분석하기 쉽지 않음
- 배치작업은 언제나 잘 고려해서 만들어야한다

## Long transaction & Query

### Idle long tx
- auto commit off에서 begin후 오래된경우

### Actice long tx
- 오랜시간동안 실행되고 있는 쿼리 트랜잭션


### 문제점
- undo log가 삭제되어야하는데 긴 트랜잭션은 이 언두 로그 삭제를 방해함
- 오랜 트랜잭션 시작시점 이후의 다른 트랜잭션들의 undo log도 삭제가 불가능해져 매우 많은 log가 쌓일수 있다
  - Community ver 기준 replica에서 오랜시간 실행되는 트랜잭션은 master에 영향을 주지 않아 괜찮았음
  - aurora mysql은 공유 스토리지를 사용하기때문에 write와 read 레플리카가 연결되어 read에서 오랜 트랜잭션시 write undo log도 삭제가 불가능해짐





